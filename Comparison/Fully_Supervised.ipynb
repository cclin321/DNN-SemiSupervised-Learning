{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e045fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U pandas numpy scikit-learn matplotlib openpyxl scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3add1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, tensorflow as tf\n",
    "print(sys.executable)\n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce68c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"Physical GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)  \n",
    "\n",
    "\n",
    "a = tf.random.normal([4000, 4000])\n",
    "b = tf.random.normal([4000, 4000])\n",
    "c = tf.matmul(a, b)\n",
    "_ = c.numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, random, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "\n",
    "random.seed(42); np.random.seed(42); tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ce641",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TARGET = \"Grid  Power\"  \n",
    "FILTER_Y_EQ_ZERO = True  \n",
    "\n",
    "\n",
    "raw_data = pd.read_excel('raw data.xlsx')\n",
    "\n",
    "\n",
    "raw_data = raw_data.drop(columns=['times'], errors='ignore').copy()\n",
    "\n",
    "\n",
    "if FILTER_Y_EQ_ZERO:\n",
    "    raw_data = raw_data[raw_data[TARGET] != 0].copy()\n",
    "\n",
    "\n",
    "num_cols = [c for c in raw_data.columns if c != TARGET]\n",
    "raw_data[num_cols] = raw_data[num_cols].apply(pd.to_numeric, errors='coerce')\n",
    "raw_data = raw_data.dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"Data shape:\", raw_data.shape)\n",
    "display(raw_data.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba17762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataset = raw_data.sample(frac=0.8, random_state=0)\n",
    "test_dataset  = raw_data.drop(train_dataset.index)\n",
    "\n",
    "\n",
    "test_x_data = test_dataset.drop(columns=[TARGET]).copy()\n",
    "test_y_data = test_dataset[TARGET].copy()\n",
    "\n",
    "\n",
    "labeled_train_data   = train_dataset.sample(frac=0.6, random_state=0).copy()\n",
    "unlabeled_train_data = train_dataset.drop(labeled_train_data.index).copy()\n",
    "\n",
    "\n",
    "unlabeled_train_data_actual = unlabeled_train_data.pop(TARGET).copy()\n",
    "labeled_data_labels         = labeled_train_data.pop(TARGET).copy()\n",
    "\n",
    "len(train_dataset), len(labeled_train_data), len(unlabeled_train_data), len(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e21e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "print(\"Columns:\", train_dataset.columns.tolist())\n",
    "\n",
    "\n",
    "feature_cols = [c for c in train_dataset.columns if c != TARGET]\n",
    "\n",
    "\n",
    "scaler_fs = StandardScaler().fit(labeled_train_data[feature_cols])\n",
    "\n",
    "\n",
    "X_fs_tr = scaler_fs.transform(labeled_train_data[feature_cols]).astype(\"float32\")\n",
    "y_fs_tr = labeled_data_labels.values.astype(\"float32\")  \n",
    "\n",
    "\n",
    "X_fs_te = scaler_fs.transform(test_dataset[feature_cols]).astype(\"float32\")\n",
    "y_fs_te = test_dataset[TARGET].values.astype(\"float32\")\n",
    "\n",
    "INPUT_DIM_FS = X_fs_tr.shape[1]\n",
    "print(\"Supervised shapes â†’ X_tr:\", X_fs_tr.shape, \" X_te:\", X_fs_te.shape, \"  INPUT_DIM_FS:\", INPUT_DIM_FS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6294c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(\n",
    "    input_dim: int,\n",
    "    layers_: int = 3,\n",
    "    units: int = 32,\n",
    "    dropout: float = 0.0,\n",
    "    l2: float = 0.0,\n",
    "    activation: str = \"relu\",      \n",
    "    learning_rate: float = 1e-3,\n",
    "    loss: str = \"mae\",\n",
    "    metrics=(\"mae\",\"mse\"),\n",
    "):\n",
    "    inputs = keras.Input(shape=(input_dim,))\n",
    "    x = inputs\n",
    "    kreg = regularizers.l2(l2) if (l2 and l2 > 0) else None\n",
    "    for _ in range(layers_):\n",
    "        x = layers.Dense(units, kernel_regularizer=kreg)(x)\n",
    "        if activation == \"leaky_relu\":\n",
    "            x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "        else:\n",
    "            x = layers.Activation(activation)(x)\n",
    "        if dropout and dropout > 0:\n",
    "            x = layers.Dropout(dropout)(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=loss,\n",
    "        metrics=list(metrics),\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040bdf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "callbacks_fs = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_mae\", patience=10, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_mae\", factor=0.5, patience=5, min_lr=1e-5),\n",
    "]\n",
    "\n",
    "model_fs = build_model(\n",
    "    INPUT_DIM_FS,\n",
    "    layers_=3, units=32, dropout=0.0, l2=0.0,\n",
    "    activation=\"relu\", learning_rate=1e-3, loss=\"mae\"\n",
    ")\n",
    "\n",
    "history_fs = model_fs.fit(\n",
    "    X_fs_tr, y_fs_tr,\n",
    "    validation_split=0.2,\n",
    "    epochs=100, batch_size=64, verbose=0,\n",
    "    callbacks=callbacks_fs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f03b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "val_fraction = 0.2\n",
    "n_all = len(X_fs_tr)\n",
    "n_val = int(round(n_all * val_fraction))\n",
    "idx_tr_in = slice(0, n_all - n_val)\n",
    "idx_va_in = slice(n_all - n_val, n_all)\n",
    "\n",
    "X_tr_in, y_tr_in = X_fs_tr[idx_tr_in], y_fs_tr[idx_tr_in]\n",
    "X_va_in, y_va_in = X_fs_tr[idx_va_in], y_fs_tr[idx_va_in]\n",
    "\n",
    "\n",
    "yhat_tr = model_fs.predict(X_tr_in, verbose=0).ravel()\n",
    "yhat_va = model_fs.predict(X_va_in, verbose=0).ravel()\n",
    "yhat_te = model_fs.predict(X_fs_te, verbose=0).ravel()\n",
    "\n",
    "def metrics_block(y_true, y_pred):\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    mse  = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "    loss = mae\n",
    "    return {\"Loss\": loss, \"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R2\": r2, \"MAPE\": mape}\n",
    "\n",
    "m_tr = metrics_block(y_tr_in, yhat_tr)\n",
    "m_va = metrics_block(y_va_in, yhat_va)\n",
    "m_te = metrics_block(y_fs_te, yhat_te)\n",
    "\n",
    "\n",
    "hist_df = pd.DataFrame(history_fs.history).copy()\n",
    "hist_df.insert(0, \"epoch\", np.arange(1, len(hist_df) + 1))\n",
    "\n",
    "\n",
    "pred_train_df = pd.DataFrame({\"y_true\": y_tr_in, \"y_pred\": yhat_tr, \"residual\": y_tr_in - yhat_tr})\n",
    "pred_val_df   = pd.DataFrame({\"y_true\": y_va_in, \"y_pred\": yhat_va, \"residual\": y_va_in - yhat_va})\n",
    "pred_test_df  = pd.DataFrame({\"y_true\": y_fs_te, \"y_pred\": yhat_te, \"residual\": y_fs_te - yhat_te})\n",
    "\n",
    "\n",
    "summary_df = pd.DataFrame.from_dict({\n",
    "    \"Train\": m_tr,\n",
    "    \"Val\":   m_va,\n",
    "    \"Test\":  m_te,\n",
    "}, orient=\"index\")[[\"Loss\",\"MAE\",\"MSE\",\"RMSE\",\"R2\",\"MAPE\"]]\n",
    "\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "\n",
    "pd.DataFrame({\"y_true\": y_fs_te, \"y_pred\": yhat_te}).to_excel(\n",
    "    \"outputs/fully_supervised_test_preds.xlsx\", index=False\n",
    ")\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(\"outputs/fully_supervised_errors.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    hist_df.to_excel(writer, sheet_name=\"history\", index=False)    \n",
    "    summary_df.to_excel(writer, sheet_name=\"summary\")            \n",
    "    pred_train_df.to_excel(writer, sheet_name=\"pred_train\", index=False)\n",
    "    pred_val_df.to_excel(writer,   sheet_name=\"pred_val\",   index=False)\n",
    "    pred_test_df.to_excel(writer,  sheet_name=\"pred_test\",  index=False)\n",
    "\n",
    "print(\"[Fully-Supervised DNN] Summary:\\n\", summary_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
