{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e045fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas numpy scikit-learn matplotlib tensorflow shap openpyxl jupyterlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3add1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, tensorflow as tf\n",
    "print(sys.executable)  \n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, random, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "random.seed(42); np.random.seed(42); tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88caa28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "TARGET = \"Grid  Power\"   \n",
    "FILTER_Y_EQ_ZERO = True \n",
    "K_NEIGHBORS = 1          \n",
    "PAIR_SAMPLE_FRAC = 0.10  \n",
    "PAIR_SAMPLE_MAX = 200_000\n",
    "EPOCHS_STAGE2 = 100\n",
    "EPOCHS_STAGE3 = 100\n",
    "SHAP_BACKGROUND_N = 200\n",
    "SHAP_SAMPLE_N = 500\n",
    "SHAP_NSAMPLES = 200      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ce641",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "raw_data = pd.read_excel('raw data.xlsx')\n",
    "\n",
    "raw_data = raw_data.drop(columns=['times'], errors='ignore').copy()\n",
    "\n",
    "\n",
    "if FILTER_Y_EQ_ZERO:\n",
    "    raw_data = raw_data[raw_data[TARGET] != 0].copy()\n",
    "\n",
    "\n",
    "num_cols = [c for c in raw_data.columns if c != TARGET]\n",
    "raw_data[num_cols] = raw_data[num_cols].apply(pd.to_numeric, errors='coerce')\n",
    "raw_data = raw_data.dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"Data shape:\", raw_data.shape)\n",
    "display(raw_data.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba17762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train/Test (80/20)\n",
    "train_dataset = raw_data.sample(frac=0.8, random_state=0)\n",
    "test_dataset  = raw_data.drop(train_dataset.index)\n",
    "\n",
    "\n",
    "test_x_data = test_dataset.drop(columns=[TARGET]).copy()\n",
    "test_y_data = test_dataset[TARGET].copy()\n",
    "\n",
    "\n",
    "labeled_train_data   = train_dataset.sample(frac=0.6, random_state=0).copy()\n",
    "unlabeled_train_data = train_dataset.drop(labeled_train_data.index).copy()\n",
    "\n",
    "\n",
    "unlabeled_train_data_actual = unlabeled_train_data.pop(TARGET).copy()\n",
    "labeled_data_labels         = labeled_train_data.pop(TARGET).copy()\n",
    "\n",
    "len(train_dataset), len(labeled_train_data), len(unlabeled_train_data), len(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b62bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_stats = train_dataset.describe().transpose()\n",
    "train_stats = train_stats.drop(index=TARGET, errors='ignore')\n",
    "\n",
    "def norm(df):\n",
    "    return (df - train_stats['mean']) / train_stats['std'].replace(0, 1.0)\n",
    "\n",
    "normed_labeled_train_data   = norm(labeled_train_data).astype('float32')\n",
    "normed_unlabeled_train_data = norm(unlabeled_train_data).astype('float32')\n",
    "normed_test_data            = norm(test_x_data).astype('float32')\n",
    "\n",
    "INPUT_DIM = normed_labeled_train_data.shape[1]\n",
    "print(\"Input dim:\", INPUT_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3186ae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=K_NEIGHBORS, metric=\"euclidean\").fit(normed_labeled_train_data.values)\n",
    "dists, idxs = nbrs.kneighbors(normed_unlabeled_train_data.values, return_distance=True)\n",
    "\n",
    "\n",
    "initial_labels = labeled_data_labels.iloc[idxs.ravel()].reset_index(drop=True)\n",
    "unlabeled_train_data_actual = unlabeled_train_data_actual.reset_index(drop=True)\n",
    "\n",
    "pd.DataFrame(initial_labels, columns=[TARGET]).to_excel('outputs/20230315_initial_labels.xlsx', index=False)\n",
    "pd.DataFrame(unlabeled_train_data_actual, columns=[TARGET]).to_excel('outputs/20230315_actual_labels.xlsx', index=False)\n",
    "\n",
    "print(\"Stage-1 finished：initial tag num\", len(initial_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6386b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ZL = normed_labeled_train_data.values.astype('float32')  # (m, p)\n",
    "yL = labeled_data_labels.values.astype('float32')\n",
    "m, p = ZL.shape\n",
    "\n",
    "\n",
    "PAIR_SAMPLE_FRAC = 0.10\n",
    "PAIR_SAMPLE_MAX  = 200_000\n",
    "BATCH_GEN        = 50_000  \n",
    "\n",
    "total_pairs = m * (m - 1) // 2\n",
    "n_sample = min(max(1, int(PAIR_SAMPLE_FRAC * total_pairs)), PAIR_SAMPLE_MAX)\n",
    "\n",
    "rng = np.random.default_rng(9)\n",
    "Xs, ys, made = [], [], 0\n",
    "while made < n_sample:\n",
    "    b = min(BATCH_GEN, n_sample - made)\n",
    "    i = rng.integers(0, m-1, size=b, endpoint=False)\n",
    "    j = rng.integers(0, m,   size=b)\n",
    "    mask = i < j\n",
    "    if not np.any(mask):\n",
    "        continue\n",
    "    i = i[mask]; j = j[mask]\n",
    "\n",
    "    Xs.append(ZL[i] - ZL[j])         # (b, p), float32\n",
    "    ys.append(yL[i] - yL[j])         # (b,)\n",
    "    made += len(i)\n",
    "\n",
    "s_feature_diff_labeled = pd.DataFrame(np.vstack(Xs).astype('float32'))\n",
    "s_target_diff          = pd.Series(np.concatenate(ys), dtype='float32')\n",
    "print(\"Stage-2 number of sampled differences:\", len(s_target_diff))\n",
    "print(\"Stage-2 number of sampled differences:\", s_feature_diff_labeled.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d693d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "def build_model(input_dim):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(loss='mae', optimizer=\"adam\", metrics=['mae','mse'])\n",
    "    return model\n",
    "'''\n",
    "\n",
    "def build_model(input_dim):\n",
    "    inputs = keras.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(32, activation=\"relu\")(inputs)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mae\", metrics=[\"mae\",\"mse\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "modification_model = build_model(INPUT_DIM)\n",
    "\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 25 == 0: print('')\n",
    "        print('.', end='')\n",
    "\n",
    "history = modification_model.fit(\n",
    "    s_feature_diff_labeled, s_target_diff,\n",
    "    epochs=EPOCHS_STAGE2, validation_split=0.2, verbose=0, callbacks=[PrintDot()]\n",
    ")\n",
    "\n",
    "hist2 = pd.DataFrame(history.history); hist2['epoch'] = history.epoch\n",
    "pd.DataFrame(hist2).to_excel('outputs/stage2_errors.xlsx', index=False)\n",
    "hist2.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modification_model.summary()\n",
    "print(\"X shape:\", s_feature_diff_labeled.shape, \"y shape:\", s_target_diff.shape, s_target_diff.dtype)\n",
    "\n",
    "\n",
    "eval_loss, eval_mae, eval_mse = modification_model.evaluate(s_feature_diff_labeled, s_target_diff, verbose=0)\n",
    "print(\"Eval -> loss/mae/mse:\", eval_loss, eval_mae, eval_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d265ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "closestL_idx = idxs.ravel()\n",
    "\n",
    "\n",
    "ZL_df = pd.DataFrame(ZL)\n",
    "ZU_df = normed_unlabeled_train_data.reset_index(drop=True)\n",
    "feature_diff_most_sim = (ZL_df.iloc[closestL_idx].values - ZU_df.values).astype('float32')\n",
    "\n",
    "\n",
    "modification_values = modification_model.predict(feature_diff_most_sim, verbose=0).ravel().astype('float32')\n",
    "\n",
    "\n",
    "final_labels_unlabeled = pd.Series(initial_labels.values + modification_values, name=TARGET).astype('float32')\n",
    "pd.DataFrame(final_labels_unlabeled).to_excel('outputs/20230315_adjusted_labels.xlsx', index=False)\n",
    "\n",
    "print(\"Stage-2 finished：Number of modified labels generated\", len(final_labels_unlabeled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd904c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "final_xtrain_data = pd.concat(\n",
    "    [normed_labeled_train_data.reset_index(drop=True),\n",
    "     normed_unlabeled_train_data.reset_index(drop=True)],\n",
    "    axis=0\n",
    ").astype('float32')\n",
    "\n",
    "\n",
    "final_ytrain_data = pd.concat(\n",
    "    [labeled_data_labels.reset_index(drop=True).astype('float32'),\n",
    "     final_labels_unlabeled.reset_index(drop=True).astype('float32')],\n",
    "    axis=0\n",
    ").squeeze()\n",
    "\n",
    "print(\"Final training data shape:\", final_xtrain_data.shape, final_ytrain_data.shape)\n",
    "\n",
    "final_model = build_model(final_xtrain_data.shape[1])\n",
    "history = final_model.fit(\n",
    "    final_xtrain_data, final_ytrain_data,\n",
    "    epochs=EPOCHS_STAGE3, validation_split=0.2, verbose=0, callbacks=[PrintDot()]\n",
    ")\n",
    "\n",
    "hist3 = pd.DataFrame(history.history); hist3['epoch'] = history.epoch\n",
    "pd.DataFrame(hist3).to_excel('outputs/stage3_errors.xlsx', index=False)\n",
    "hist3.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b795b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_predictions = final_model.predict(normed_test_data, verbose=0).ravel()\n",
    "pd.DataFrame({\"y_pred\": test_predictions}).to_excel('outputs/20230406_DSSL_predictions.xlsx', index=False)\n",
    "pd.DataFrame(test_y_data).to_excel('outputs/20230406_test_actual.xlsx', index=False)\n",
    "pd.DataFrame(test_x_data).to_excel('outputs/20230406_test_X.xlsx', index=False)\n",
    "\n",
    "loss, mae, mse = final_model.evaluate(normed_test_data, test_y_data, verbose=0)\n",
    "print(\"loss:\", loss, \"MAE:\", mae, \"MSE:\", mse)\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "print(\"R2 :\", r2_score(test_y_data, test_predictions))\n",
    "print(\"MAPE:\", mean_absolute_percentage_error(test_y_data, test_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94552940",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import shap\n",
    "\n",
    "feat_names = final_xtrain_data.columns.tolist()\n",
    "\n",
    "\n",
    "bg_n = min(SHAP_BACKGROUND_N, len(final_xtrain_data))\n",
    "smpl_n = min(SHAP_SAMPLE_N, len(final_xtrain_data))\n",
    "background = final_xtrain_data.sample(n=bg_n, random_state=42)\n",
    "X_sample  = final_xtrain_data.sample(n=smpl_n, random_state=7)\n",
    "\n",
    "def f_predict(x):\n",
    "    return final_model.predict(x, verbose=0)\n",
    "\n",
    "explainer   = shap.KernelExplainer(f_predict, background)\n",
    "shap_values = explainer.shap_values(X_sample, nsamples=SHAP_NSAMPLES)\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[0]\n",
    "\n",
    "print(\"SHAP finished：\", np.array(shap_values).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84db54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "\n",
    "sv = np.array(shap_values).squeeze()   # e.g. (500, 25)\n",
    "assert sv.ndim == 2, f\"sv ndim should be 2, got {sv.shape}\"\n",
    "\n",
    "\n",
    "base = explainer.expected_value\n",
    "if isinstance(base, (list, np.ndarray)):\n",
    "    base = float(np.squeeze(base))\n",
    "\n",
    "\n",
    "imp = np.mean(np.abs(sv), axis=0).ravel()      # (M,)\n",
    "order = np.argsort(imp)[::-1]\n",
    "top3  = [feat_names[i] for i in order[:3]]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "shap.summary_plot(sv, X_sample, feature_names=feat_names, plot_type=\"bar\", show=False)\n",
    "plt.tight_layout(); plt.savefig(\"outputs/shap_top10_bar.png\", dpi=220); plt.close()\n",
    "\n",
    "plt.figure()\n",
    "shap.summary_plot(sv, X_sample, feature_names=feat_names, show=False)\n",
    "plt.tight_layout(); plt.savefig(\"outputs/shap_beeswarm.png\", dpi=220); plt.close()\n",
    "\n",
    "\n",
    "pd.DataFrame({\"feature\": feat_names, \"mean_abs_shap\": imp}) \\\n",
    "  .sort_values(\"mean_abs_shap\", ascending=False) \\\n",
    "  .to_csv(\"outputs/shap_global_importance.csv\", index=False)\n",
    "\n",
    "\n",
    "for f in top3:\n",
    "    plt.figure()\n",
    "    shap.dependence_plot(f, sv, X_sample, feature_names=feat_names,\n",
    "                         interaction_index=\"auto\", show=False)\n",
    "    plt.tight_layout(); plt.savefig(f\"outputs/shap_dependence_{f}.png\", dpi=220); plt.close()\n",
    "\n",
    "\n",
    "for k, (_, row) in enumerate(X_sample.head(3).iterrows(), start=1):\n",
    "    sv_row = sv[k-1]  \n",
    "    exp = shap.Explanation(values=sv_row,\n",
    "                           base_values=base,\n",
    "                           data=row.values,\n",
    "                           feature_names=feat_names)\n",
    "    shap.plots.waterfall(exp, max_display=15, show=False)\n",
    "    plt.tight_layout(); plt.savefig(f\"outputs/shap_waterfall_case{k}.png\", dpi=220); plt.close()\n",
    "\n",
    "\n",
    "pred = final_model.predict(X_sample, verbose=0).reshape(-1)\n",
    "gap  = np.max(np.abs(pred - (base + sv.sum(axis=1))))\n",
    "print(\"Top-3 characteristic：\", \", \".join(top3))\n",
    "print(\"max|pred - (base + sum(shap))| =\", float(gap))\n",
    "print(\"SHAP image file and CSV export to outputs/ files\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
