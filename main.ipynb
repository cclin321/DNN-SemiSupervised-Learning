{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e045fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas numpy scikit-learn matplotlib tensorflow shap openpyxl jupyterlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3add1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, tensorflow as tf\n",
    "print(sys.executable)  \n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, random, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "random.seed(42); np.random.seed(42); tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88caa28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "TARGET = \"Grid  Power\"   \n",
    "FILTER_Y_EQ_ZERO = True \n",
    "K_NEIGHBORS = 1          \n",
    "PAIR_SAMPLE_FRAC = 0.10 \n",
    "PAIR_SAMPLE_MAX = 200_000\n",
    "EPOCHS_STAGE2 = 100\n",
    "EPOCHS_STAGE3 = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ce641",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "raw_data = pd.read_excel('raw data.xlsx')\n",
    "\n",
    "raw_data = raw_data.drop(columns=['times'], errors='ignore').copy()\n",
    "\n",
    "\n",
    "if FILTER_Y_EQ_ZERO:\n",
    "    raw_data = raw_data[raw_data[TARGET] != 0].copy()\n",
    "\n",
    "\n",
    "num_cols = [c for c in raw_data.columns if c != TARGET]\n",
    "raw_data[num_cols] = raw_data[num_cols].apply(pd.to_numeric, errors='coerce')\n",
    "raw_data = raw_data.dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"Data shape:\", raw_data.shape)\n",
    "display(raw_data.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba17762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train/Test (80/20)\n",
    "train_dataset = raw_data.sample(frac=0.8, random_state=0)\n",
    "test_dataset  = raw_data.drop(train_dataset.index)\n",
    "\n",
    "\n",
    "test_x_data = test_dataset.drop(columns=[TARGET]).copy()\n",
    "test_y_data = test_dataset[TARGET].copy()\n",
    "\n",
    "\n",
    "labeled_train_data   = train_dataset.sample(frac=0.6, random_state=0).copy()\n",
    "unlabeled_train_data = train_dataset.drop(labeled_train_data.index).copy()\n",
    "\n",
    "\n",
    "unlabeled_train_data_actual = unlabeled_train_data.pop(TARGET).copy()\n",
    "labeled_data_labels         = labeled_train_data.pop(TARGET).copy()\n",
    "\n",
    "len(train_dataset), len(labeled_train_data), len(unlabeled_train_data), len(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b62bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_stats = train_dataset.describe().transpose()\n",
    "train_stats = train_stats.drop(index=TARGET, errors='ignore')\n",
    "\n",
    "def norm(df):\n",
    "    return (df - train_stats['mean']) / train_stats['std'].replace(0, 1.0)\n",
    "\n",
    "normed_labeled_train_data   = norm(labeled_train_data).astype('float32')\n",
    "normed_unlabeled_train_data = norm(unlabeled_train_data).astype('float32')\n",
    "normed_test_data            = norm(test_x_data).astype('float32')\n",
    "\n",
    "INPUT_DIM = normed_labeled_train_data.shape[1]\n",
    "print(\"Input dim:\", INPUT_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3186ae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=K_NEIGHBORS, metric=\"euclidean\").fit(normed_labeled_train_data.values)\n",
    "dists, idxs = nbrs.kneighbors(normed_unlabeled_train_data.values, return_distance=True)\n",
    "\n",
    "\n",
    "initial_labels = labeled_data_labels.iloc[idxs.ravel()].reset_index(drop=True)\n",
    "unlabeled_train_data_actual = unlabeled_train_data_actual.reset_index(drop=True)\n",
    "\n",
    "pd.DataFrame(initial_labels, columns=[TARGET]).to_excel('outputs/20230315_initial_labels.xlsx', index=False)\n",
    "pd.DataFrame(unlabeled_train_data_actual, columns=[TARGET]).to_excel('outputs/20230315_actual_labels.xlsx', index=False)\n",
    "\n",
    "print(\"Stage-1 finished：initial tag num\", len(initial_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6386b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ZL = normed_labeled_train_data.values.astype('float32')  # (m, p)\n",
    "yL = labeled_data_labels.values.astype('float32')\n",
    "m, p = ZL.shape\n",
    "\n",
    "\n",
    "PAIR_SAMPLE_FRAC = 0.10\n",
    "PAIR_SAMPLE_MAX  = 200_000\n",
    "BATCH_GEN        = 50_000  \n",
    "\n",
    "total_pairs = m * (m - 1) // 2\n",
    "n_sample = min(max(1, int(PAIR_SAMPLE_FRAC * total_pairs)), PAIR_SAMPLE_MAX)\n",
    "\n",
    "rng = np.random.default_rng(9)\n",
    "Xs, ys, made = [], [], 0\n",
    "while made < n_sample:\n",
    "    b = min(BATCH_GEN, n_sample - made)\n",
    "    i = rng.integers(0, m-1, size=b, endpoint=False)\n",
    "    j = rng.integers(0, m,   size=b)\n",
    "    mask = i < j\n",
    "    if not np.any(mask):\n",
    "        continue\n",
    "    i = i[mask]; j = j[mask]\n",
    "\n",
    "    Xs.append(ZL[i] - ZL[j])         # (b, p), float32\n",
    "    ys.append(yL[i] - yL[j])         # (b,)\n",
    "    made += len(i)\n",
    "\n",
    "s_feature_diff_labeled = pd.DataFrame(np.vstack(Xs).astype('float32'))\n",
    "s_target_diff          = pd.Series(np.concatenate(ys), dtype='float32')\n",
    "print(\"Stage-2 number of sampled differences:\", len(s_target_diff))\n",
    "print(\"Stage-2 number of sampled differences:\", s_feature_diff_labeled.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d693d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "def build_model(input_dim):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(loss='mae', optimizer=\"adam\", metrics=['mae','mse'])\n",
    "    return model\n",
    "'''\n",
    "\n",
    "def build_model(input_dim):\n",
    "    inputs = keras.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(32, activation=\"relu\")(inputs)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mae\", metrics=[\"mae\",\"mse\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "modification_model = build_model(INPUT_DIM)\n",
    "\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 25 == 0: print('')\n",
    "        print('.', end='')\n",
    "\n",
    "history = modification_model.fit(\n",
    "    s_feature_diff_labeled, s_target_diff,\n",
    "    epochs=EPOCHS_STAGE2, validation_split=0.2, verbose=0, callbacks=[PrintDot()]\n",
    ")\n",
    "\n",
    "hist2 = pd.DataFrame(history.history); hist2['epoch'] = history.epoch\n",
    "pd.DataFrame(hist2).to_excel('outputs/stage2_errors.xlsx', index=False)\n",
    "hist2.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modification_model.summary()\n",
    "print(\"X shape:\", s_feature_diff_labeled.shape, \"y shape:\", s_target_diff.shape, s_target_diff.dtype)\n",
    "\n",
    "\n",
    "eval_loss, eval_mae, eval_mse = modification_model.evaluate(s_feature_diff_labeled, s_target_diff, verbose=0)\n",
    "print(\"Eval -> loss/mae/mse:\", eval_loss, eval_mae, eval_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d265ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "closestL_idx = idxs.ravel()\n",
    "\n",
    "\n",
    "ZL_df = pd.DataFrame(ZL)\n",
    "ZU_df = normed_unlabeled_train_data.reset_index(drop=True)\n",
    "feature_diff_most_sim = (ZL_df.iloc[closestL_idx].values - ZU_df.values).astype('float32')\n",
    "\n",
    "\n",
    "modification_values = modification_model.predict(feature_diff_most_sim, verbose=0).ravel().astype('float32')\n",
    "\n",
    "\n",
    "final_labels_unlabeled = pd.Series(initial_labels.values + modification_values, name=TARGET).astype('float32')\n",
    "pd.DataFrame(final_labels_unlabeled).to_excel('outputs/20230315_adjusted_labels.xlsx', index=False)\n",
    "\n",
    "print(\"Stage-2 finished：Number of modified labels generated\", len(final_labels_unlabeled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd904c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "final_xtrain_data = pd.concat(\n",
    "    [normed_labeled_train_data.reset_index(drop=True),\n",
    "     normed_unlabeled_train_data.reset_index(drop=True)],\n",
    "    axis=0\n",
    ").astype('float32')\n",
    "\n",
    "\n",
    "final_ytrain_data = pd.concat(\n",
    "    [labeled_data_labels.reset_index(drop=True).astype('float32'),\n",
    "     final_labels_unlabeled.reset_index(drop=True).astype('float32')],\n",
    "    axis=0\n",
    ").squeeze()\n",
    "\n",
    "print(\"Final training data shape:\", final_xtrain_data.shape, final_ytrain_data.shape)\n",
    "\n",
    "final_model = build_model(final_xtrain_data.shape[1])\n",
    "history = final_model.fit(\n",
    "    final_xtrain_data, final_ytrain_data,\n",
    "    epochs=EPOCHS_STAGE3, validation_split=0.2, verbose=0, callbacks=[PrintDot()]\n",
    ")\n",
    "\n",
    "hist3 = pd.DataFrame(history.history); hist3['epoch'] = history.epoch\n",
    "pd.DataFrame(hist3).to_excel('outputs/stage3_errors.xlsx', index=False)\n",
    "hist3.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b795b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_predictions = final_model.predict(normed_test_data, verbose=0).ravel()\n",
    "pd.DataFrame({\"y_pred\": test_predictions}).to_excel('outputs/20230406_DSSL_predictions.xlsx', index=False)\n",
    "pd.DataFrame(test_y_data).to_excel('outputs/20230406_test_actual.xlsx', index=False)\n",
    "pd.DataFrame(test_x_data).to_excel('outputs/20230406_test_X.xlsx', index=False)\n",
    "\n",
    "loss, mae, mse = final_model.evaluate(normed_test_data, test_y_data, verbose=0)\n",
    "print(\"loss:\", loss, \"MAE:\", mae, \"MSE:\", mse)\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "print(\"R2 :\", r2_score(test_y_data, test_predictions))\n",
    "print(\"MAPE:\", mean_absolute_percentage_error(test_y_data, test_predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
