{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e045fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U pandas numpy scikit-learn matplotlib openpyxl scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3add1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, tensorflow as tf\n",
    "print(sys.executable)  \n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, random, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "\n",
    "random.seed(42); np.random.seed(42); tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ce641",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"Grid  Power\"  \n",
    "FILTER_Y_EQ_ZERO = True   \n",
    "\n",
    "\n",
    "raw_data = pd.read_excel('raw data.xlsx')\n",
    "\n",
    "\n",
    "raw_data = raw_data.drop(columns=['times'], errors='ignore').copy()\n",
    "\n",
    "\n",
    "if FILTER_Y_EQ_ZERO:\n",
    "    raw_data = raw_data[raw_data[TARGET] != 0].copy()\n",
    "\n",
    "\n",
    "num_cols = [c for c in raw_data.columns if c != TARGET]\n",
    "raw_data[num_cols] = raw_data[num_cols].apply(pd.to_numeric, errors='coerce')\n",
    "raw_data = raw_data.dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"Data shape:\", raw_data.shape)\n",
    "display(raw_data.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aabf0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train/Test (80/20)\n",
    "train_dataset = raw_data.sample(frac=0.8, random_state=0)\n",
    "test_dataset  = raw_data.drop(train_dataset.index)\n",
    "\n",
    "\n",
    "test_x_data = test_dataset.drop(columns=[TARGET]).copy()\n",
    "test_y_data = test_dataset[TARGET].copy()\n",
    "\n",
    "\n",
    "labeled_train_data   = train_dataset.sample(frac=0.6, random_state=0).copy()\n",
    "unlabeled_train_data = train_dataset.drop(labeled_train_data.index).copy()\n",
    "\n",
    "\n",
    "unlabeled_train_data_actual = unlabeled_train_data.pop(TARGET).copy()\n",
    "labeled_data_labels         = labeled_train_data.pop(TARGET).copy()\n",
    "\n",
    "len(train_dataset), len(labeled_train_data), len(unlabeled_train_data), len(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef99ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "print(\"Columns:\", train_dataset.columns.tolist())\n",
    "\n",
    "\n",
    "feature_cols = [c for c in train_dataset.columns if c != TARGET]\n",
    "\n",
    "\n",
    "scaler_fs = StandardScaler().fit(labeled_train_data[feature_cols])\n",
    "\n",
    "X_fs_tr = scaler_fs.transform(labeled_train_data[feature_cols]).astype(\"float32\")\n",
    "y_fs_tr = labeled_data_labels.values.astype(\"float32\")  \n",
    "\n",
    "\n",
    "X_fs_te = scaler_fs.transform(test_dataset[feature_cols]).astype(\"float32\")\n",
    "y_fs_te = test_dataset[TARGET].values.astype(\"float32\")\n",
    "\n",
    "INPUT_DIM_FS = X_fs_tr.shape[1]\n",
    "print(\"Supervised shapes → X_tr:\", X_fs_tr.shape, \" X_te:\", X_fs_te.shape, \"  INPUT_DIM_FS:\", INPUT_DIM_FS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc56777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === data prep ===\n",
    "\n",
    "\n",
    "X_u = scaler_fs.transform(unlabeled_train_data[feature_cols]).astype(\"float32\")\n",
    "\n",
    "\n",
    "n_all = X_fs_tr.shape[0]\n",
    "n_val = int(round(n_all * 0.20))\n",
    "X_l_tr, y_l_tr = X_fs_tr[:n_all - n_val], y_fs_tr[:n_all - n_val]\n",
    "X_l_va, y_l_va = X_fs_tr[n_all - n_val:], y_fs_tr[n_all - n_val:]\n",
    "\n",
    "X_u.shape, X_l_tr.shape, X_l_va.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c3fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    build_model\n",
    "except NameError:\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers, regularizers\n",
    "    def build_regressor(input_dim, layers_=3, units=32, dropout=0.0, l2=0.0,\n",
    "                        activation=\"relu\", learning_rate=1e-3, loss=\"mae\",\n",
    "                        metrics=(\"mae\",\"mse\")):\n",
    "        inputs = keras.Input(shape=(input_dim,))\n",
    "        x = inputs\n",
    "        kreg = regularizers.l2(l2) if (l2 and l2 > 0) else None\n",
    "        for _ in range(layers_):\n",
    "            x = layers.Dense(units, kernel_regularizer=kreg)(x)\n",
    "            if activation == \"leaky_relu\":\n",
    "                x = layers.LeakyReLU(0.2)(x)\n",
    "            else:\n",
    "                x = layers.Activation(activation)(x)\n",
    "            if dropout and dropout > 0:\n",
    "                x = layers.Dropout(dropout)(x)\n",
    "        outputs = layers.Dense(1)(x)\n",
    "        model = keras.Model(inputs, outputs)\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                      loss=loss, metrics=list(metrics))\n",
    "        return model\n",
    "    build_model = build_regressor\n",
    "\n",
    "import tensorflow as tf\n",
    "def mc_predict(model, X, T=20, batch_size=512):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    for _ in range(T):\n",
    "        y = model(X, training=True)  \n",
    "        preds.append(tf.squeeze(y, axis=-1).numpy())\n",
    "    preds = np.stack(preds, axis=0)  # [T, N]\n",
    "    return preds.mean(0), preds.std(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5bf7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "LR_WARM   = 1e-3    \n",
    "EPOCHS_W  = 100\n",
    "DROPOUT_M = 0.2      \n",
    "T_MC      = 30       \n",
    "PCT_KEEP  = 0.3     \n",
    "MIN_KEEP  = max(200, int(0.1 * len(X_u)))  \n",
    "\n",
    "warm = build_model(INPUT_DIM_FS, layers_=3, units=32, dropout=DROPOUT_M, l2=0.0,\n",
    "                   activation=\"relu\", learning_rate=LR_WARM, loss=\"mae\")\n",
    "warm.fit(\n",
    "    X_l_tr, y_l_tr,\n",
    "    validation_data=(X_l_va, y_l_va),\n",
    "    epochs=EPOCHS_W, batch_size=64, verbose=0,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_mae\", patience=10, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor=\"val_mae\", factor=0.5, patience=5, min_lr=1e-5),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "u_mean, u_std = mc_predict(warm, X_u, T=T_MC, batch_size=1024)\n",
    "\n",
    "\n",
    "k = max(int(len(X_u) * PCT_KEEP), MIN_KEEP)\n",
    "idx = np.argsort(u_std)[:k]\n",
    "X_pseudo = X_u[idx]\n",
    "y_pseudo = u_mean[idx]\n",
    "std_pseudo = u_std[idx]\n",
    "\n",
    "print(f\"Unlabeled = {len(X_u)}  →  kept {len(X_pseudo)} pseudo-labels (PCT_KEEP={PCT_KEEP})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d11009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "ALPHA_PSEUDO = 0.5  \n",
    "X_pl_tr = np.concatenate([X_l_tr, X_pseudo], axis=0)\n",
    "y_pl_tr = np.concatenate([y_l_tr, y_pseudo], axis=0)\n",
    "w_pl_tr = np.concatenate([np.ones(len(X_l_tr)), ALPHA_PSEUDO * np.ones(len(X_pseudo))], axis=0)\n",
    "\n",
    "\n",
    "final_pl = build_model(INPUT_DIM_FS, layers_=3, units=32, dropout=0.0, l2=0.0,\n",
    "                       activation=\"relu\", learning_rate=1e-3, loss=\"mae\")\n",
    "\n",
    "final_hist = final_pl.fit(\n",
    "    X_pl_tr, y_pl_tr,\n",
    "    validation_data=(X_l_va, y_l_va),\n",
    "    epochs=100, batch_size=64, verbose=0,\n",
    "    sample_weight=w_pl_tr,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_mae\", patience=12, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor=\"val_mae\", factor=0.5, patience=6, min_lr=1e-5),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79548515",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mb(y_true, y_pred):\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    mse  = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    return {\"Loss\": mae, \"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R2\": r2, \"MAPE\": mape}\n",
    "\n",
    "yhat_tr = final_pl.predict(X_l_tr, verbose=0).ravel()\n",
    "yhat_va = final_pl.predict(X_l_va, verbose=0).ravel()\n",
    "yhat_te = final_pl.predict(X_fs_te, verbose=0).ravel()\n",
    "\n",
    "m_tr = mb(y_l_tr, yhat_tr)\n",
    "m_va = mb(y_l_va, yhat_va)\n",
    "m_te = mb(y_fs_te, yhat_te)\n",
    "\n",
    "summary_df = pd.DataFrame.from_dict({\"Train\": m_tr, \"Val\": m_va, \"Test\": m_te}, orient=\"index\")[[\"Loss\",\"MAE\",\"MSE\",\"RMSE\",\"R2\",\"MAPE\"]]\n",
    "print(\"[Pseudo-Labeling] Summary:\\n\", summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9fc709",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "pd.DataFrame({\"y_true\": y_fs_te, \"y_pred\": yhat_te}).to_excel(\"outputs/pseudolabel_test_preds.xlsx\", index=False)\n",
    "\n",
    "with pd.ExcelWriter(\"outputs/pseudolabel_errors.xlsx\", engine=\"openpyxl\") as w:\n",
    "    summary_df.to_excel(w, sheet_name=\"summary\")\n",
    "    pd.DataFrame({\"y_true\": y_l_tr, \"y_pred\": yhat_tr, \"residual\": y_l_tr - yhat_tr}).to_excel(w, sheet_name=\"pred_train\", index=False)\n",
    "    pd.DataFrame({\"y_true\": y_l_va, \"y_pred\": yhat_va, \"residual\": y_l_va - yhat_va}).to_excel(w, sheet_name=\"pred_val\", index=False)\n",
    "    pd.DataFrame({\"y_true\": y_fs_te, \"y_pred\": yhat_te, \"residual\": y_fs_te - yhat_te}).to_excel(w, sheet_name=\"pred_test\", index=False)\n",
    "    \n",
    "    pd.DataFrame({\"idx_in_unlabeled\": idx, \"pseudo_y\": y_pseudo, \"std\": std_pseudo}).to_excel(w, sheet_name=\"pseudo_selected\", index=False)\n",
    "\n",
    "\n",
    "hist_df = pd.DataFrame(final_hist.history); hist_df[\"epoch\"] = np.arange(1, len(hist_df)+1)\n",
    "hist_df.to_excel(\"outputs/pseudolabel_history.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
